{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\diego\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB 660.6 kB/s eta 0:02:31\n",
      "   ---------------------------------------- 0.1/99.8 MB 1.7 MB/s eta 0:00:59\n",
      "   ---------------------------------------- 0.6/99.8 MB 5.1 MB/s eta 0:00:20\n",
      "    --------------------------------------- 1.7/99.8 MB 9.8 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 3.6/99.8 MB 16.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 7.1/99.8 MB 26.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 10.4/99.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 14.1/99.8 MB 81.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 16.4/99.8 MB 73.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 20.6/99.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 30.8/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 36.2/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 41.7/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 47.0/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 52.6/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 57.0/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 62.0/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 67.2/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 72.6/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 78.1/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 83.4/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 88.7/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.2/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.2/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.2/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 94.0/99.8 MB 43.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.3/99.8 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 29.8 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2701467 entries, 0 to 2701466\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Dtype \n",
      "---  ------                     ----- \n",
      " 0   EstablecimientoGlosa       object\n",
      " 1   RegionGlosa                object\n",
      " 2   ComunaGlosa                object\n",
      " 3   TipoEstablecimiento        object\n",
      " 4   DependenciaAdministrativa  object\n",
      " 5   Latitud                    object\n",
      " 6   Longitud                   object\n",
      " 7   Anio                       int32 \n",
      " 8   SemanaEstadistica          int32 \n",
      " 9   Causa                      object\n",
      " 10  NumTotal                   int32 \n",
      "dtypes: int32(3), object(8)\n",
      "memory usage: 195.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2699799 entries, 0 to 2701466\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Dtype \n",
      "---  ------                     ----- \n",
      " 0   EstablecimientoGlosa       object\n",
      " 1   RegionGlosa                object\n",
      " 2   ComunaGlosa                object\n",
      " 3   TipoEstablecimiento        object\n",
      " 4   DependenciaAdministrativa  object\n",
      " 5   Latitud                    object\n",
      " 6   Longitud                   object\n",
      " 7   Anio                       int32 \n",
      " 8   SemanaEstadistica          int32 \n",
      " 9   Causa                      object\n",
      " 10  NumTotal                   int32 \n",
      "dtypes: int32(3), object(8)\n",
      "memory usage: 216.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Dataframes\n",
    "# Read .parquet file for epimediologic data from Chile\n",
    "df_data_epi = pd.read_parquet('at_urg_respiratorio_semanal.parquet')\n",
    "\n",
    "# Drop columns not interested\n",
    "cols_interested = ['EstablecimientoGlosa','RegionGlosa','ComunaGlosa','TipoEstablecimiento','DependenciaAdministrativa',\n",
    "                   'Latitud','Longitud','Anio','SemanaEstadistica','Causa','NumTotal']\n",
    "df_model = df_data_epi[cols_interested]\n",
    "\n",
    "# Preprocessing\n",
    "# Drop NaNs\n",
    "df_model.info()\n",
    "df_model = df_model.dropna()\n",
    "df_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration of features\n",
    "\n",
    "#PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted: 1668\n"
     ]
    }
   ],
   "source": [
    "# Assign X and y \n",
    "Xcols_interested = ['EstablecimientoGlosa','RegionGlosa','ComunaGlosa','TipoEstablecimiento','DependenciaAdministrativa',\n",
    "                    'Latitud','Longitud','Anio','SemanaEstadistica','Causa']\n",
    "X_df= df_model[Xcols_interested]\n",
    "y_df= df_model[['NumTotal']]\n",
    "\n",
    "# Se borraron \n",
    "deleted = 2701467 - 2699799     #obtenido de los .info() de arriba\n",
    "print(f'deleted: {deleted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento y modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diego\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for standarization and onehotencoding\n",
    "# Identify categorical columns\n",
    "categorical_features = X_df.select_dtypes(include=['object']).columns\n",
    "numeric_features = X_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Instantiate a preprocessor \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size= 0.2,random_state=27 )\n",
    "\n",
    "# Transformation via preprocessor\n",
    "X_train_s = preprocessor.fit_transform(X_train)\n",
    "X_test_s = preprocessor.transform(X_test)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'linear': LinearRegression(),\n",
    "    'svr': SVR(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'decision_tree': DecisionTreeRegressor(),\n",
    "    'knn': KNeighborsRegressor() }\n",
    "results = []\n",
    "\n",
    "# Cros-validation\n",
    "for name, model in models.items():\n",
    "    kf = KFold(n_splits=6, random_state=27, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train_s, y_train, cv=kf)\n",
    "    results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance, fit models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_s, y_train)\n",
    "    test_score = model.score(X_test_s, y_test)\n",
    "    print(\"{} Test Set Accuracy: {}\".format(name, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lo siguiente son pruebas que quiero guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'Ridge()' (type <class 'sklearn.linear_model._ridge.Ridge'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Fit pipeline\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Check pipeline detail or structure\u001b[39;00m\n\u001b[0;32m     22\u001b[0m set_config(display\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagram\u001b[39m\u001b[38;5;124m'\u001b[39m)       \u001b[38;5;66;03m#revisar\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Diego\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Diego\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:339\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps):\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;66;03m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps)\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_steps()\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;66;03m# Setup the memory\u001b[39;00m\n\u001b[0;32m    341\u001b[0m     memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n",
      "File \u001b[1;32mc:\\Users\\Diego\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:230\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m    228\u001b[0m         t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m     ):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll intermediate steps should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers and implement fit and transform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor be the string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (t, \u001b[38;5;28mtype\u001b[39m(t))\n\u001b[0;32m    235\u001b[0m         )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    239\u001b[0m     estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    242\u001b[0m ):\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'Ridge()' (type <class 'sklearn.linear_model._ridge.Ridge'>) doesn't"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size= 0.2,random_state=27 )\n",
    "\n",
    "# Steps of the pipeline\n",
    "steps = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge()),\n",
    "    ('lasso', Lasso()),\n",
    "    ('linear', LinearRegression()),\n",
    "    ('svr', SVR()),\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('decision_tree', DecisionTreeRegressor()),\n",
    "    ('kn', KNeighborsRegressor())]\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Check pipeline detail or structure\n",
    "set_config(display='diagram')       #revisar\n",
    "pipeline\n",
    "\n",
    "# Evaluate model \n",
    "scores = pipeline.score(X_test, y_test)\n",
    "print('accuracy: %.3f' % scores)\n",
    "\n",
    "# Predict on model\n",
    "pred = pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apuntes mientras creo modelo\n",
    "- debo hacer pipelines distintas si es que evaluo métricas distintas ? como si en algunos evaluo el rmse y r squared, o ocupo distintas variables para crear la curva roc ?\n",
    "- cuantos tipos de modelo usaré ? todos los que tengo disponibles o algunos ?\n",
    "- podría crear dummy variables para ciertas columnas, pero cuales ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
